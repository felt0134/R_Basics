---
title: "Lab 5: Bison growth dynamics"
tutorial:
  id: "week_7_lab4"
output: 
  learnr::tutorial:
    progressive: true
runtime: shiny_prerendered
description: "Using tidy functions to explore bison growth data"
---

```{r setup, include=FALSE}
library(learnr)
knitr::opts_chunk$set(echo = FALSE)
gradethis::gradethis_setup()
options(tutorial.event_recorder = tutorialize::recorder)
options(tutorial.storage = learnr::filesystem_storage(file.path(path.expand("~"), "_learnr_storage_")))
```

## This is not written yet!

### Long-term ecological research on Bison in the Great Plains



### Another tidy function: summarise()



### Refresher on the distinct() function


What `%>%` does, ultimately, is *place the output of a function into the first argument of the next function*. Hence it unlocks the ability to "chain" function together and build a data analysis "pipeline". The pipe operator is especially useful with tidy functions (e.g., `filter()`) because the first argument you pass into these functions is a dataframe.

### Highlighting the utility of the pipe operator

In the previous tutorial, we performed manipulations on the iris dataframe in a sequential way. You will often need to do sequential manipulations on dataframes and there are a couple ways to do this in practice. One is to assign a new name to each intermediate dataframe created:

```{r demo_1, exercise = TRUE}

#create a new dataframe for each manipulation
iris_1 <- dplyr::mutate(iris,Petal.Area = Petal.Length*Petal.Width)
iris_2 <- dplyr::filter(iris_1,Petal.Area > mean(Petal.Area))
iris_3 <- dplyr::select(iris_2,c(Species,Petal.Area))
iris_4 <- dplyr::arrange(iris_3,desc(Petal.Area))
head(iris_4,1)

```

The code above works, but we are left with a bunch of junk in our global environment: intermediate dataframes that we don't really need and that will eat up memory. In addition, we have to keep track of which dataframe name goes into which function. This is tedious and heightens the risk of errors. The less junk the better.

We could alternatively just name every intermediary the same thing, but this is also less than ideal; it becomes easy to lose track of which version of the dataframe is which, especially when troubleshooting your code. This enhances this risk of errors.

```{r demo_2, exercise = TRUE}

#create a new dataframe for each manipulation, but keep the name the same
iris <- dplyr::mutate(iris,Petal.Area = Petal.Length*Petal.Width)
iris <- dplyr::filter(iris,Petal.Area > mean(Petal.Area))
iris <- dplyr::select(iris,c(Species,Petal.Area))
iris <- dplyr::arrange(iris,desc(Petal.Area))
head(iris,1)

```

We can eliminate junk in our global environment and the risk of error while reducing the amount of code written and enhancing the speed of our analysis using the `%>%` pipe operator. Remember, this operator automatically places the output of a function (e.g., a dataframe) into the first argument of the next function.

If we wanted to chain the first two functions together in the previous examples, it would look as
such:
```{r demo_3, exercise = TRUE}

#Use %>% to chain functions together
iris_filtered <- iris %>%  #places iris dataframe in first argument of mutate()
  dplyr::mutate(Petal.Area = Petal.Length*Petal.Width) %>%
  dplyr::filter(Petal.Area > mean(Petal.Area))

#take a look
head(iris_filtered,3)

```

Notice how there is now no longer a dataframe name passed into the first argument of *any* of the functions used; %>% is doing that for us automatically! Importantly, %>% is feedingeach function (here, on the next line) whatever dataframe has been supplied/created (here, to the left of %>%). So, the mutate() function was supplied the original iris dataframe, whereas the filter() function was supplied the dataframe that the mutate() function produced (a dataframe with Petal.Area added as a column). Thus, the pipe operator is allowing us to run functions sequentially.

If we want to add in the additional two tasks fromt he previous tutorial, it would look like this:


```{r demo_4, exercise = TRUE}

#Use %>% to chain functions together
iris %>% 
  dplyr::mutate(Petal.Area = Petal.Length*Petal.Width) %>% 
  dplyr::filter(Petal.Area > mean(Petal.Area)) %>%
  dplyr::select(c(Species,Petal.Area)) %>%
  dplyr::arrange(desc(Petal.Area)) %>% #places the final product in head() function
  head(3)
  
```

Remember, *the pipe operator `%>%` places the output of a function (e.g., a dataframe) into the first argument of the next function*. 

## Submitting tutorial results

Great job!  You've completed the assignment!  Now it's time to turn it in...

In the console, enter the following (case sensitive):

```{r, echo=TRUE, eval=FALSE}
ENSC311::submit_ENSC311()
```

Your should see something like this:

```{r}
"Week_7_lab_311_<Posit_Cloud_ID>"
```

where the end of the character string is an ID that Posit Cloud assigned you. As you do more tutorials, this list of tutorials you have run will get longer. You must pass the number that corresponds to this assignments. For example, *if* you wanted to turn in the first item on the list, you would enter: ENSC311::submit_ENSC311(1).

A "submit_ENSC311_..." file will appear under the "Files" tab in the lower right pane of RStudio.  Check the box next to the submit file and choose "Export..." from the "More" dropdown on the bar at the top of the tab.  Download the file and sumbit it to D2L.

That's it!  You're all done!

